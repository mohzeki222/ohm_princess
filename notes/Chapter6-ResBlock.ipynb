{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chainer.optimizers as Opt\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "import chainer.datasets as ds\n",
    "import chainer.dataset.convert as con\n",
    "from chainer.iterators import SerialIterator as siter\n",
    "from chainer import Variable,Chain,config,cuda\n",
    "\n",
    "import princess as ohm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = ds.get_cifar10()\n",
    "xtrain,ttrain = con.concat_examples(train)\n",
    "xtest,ttest = con.concat_examples(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 3 32 32\n"
     ]
    }
   ],
   "source": [
    "Dtrain,ch,Ny,Nx = xtrain.shape\n",
    "print(Dtrain,ch,Ny,Nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(Chain):\n",
    "    def __init__(self, ch, bn=True):\n",
    "        layers = {}\n",
    "        layers['conv1'] = L.Convolution2D(ch,ch,3,1,1)\n",
    "        layers['conv2'] = L.Convolution2D(ch,ch,3,1,1)\n",
    "        layers['bnorm1'] = L.BatchNormalization(ch)\n",
    "        layers['bnorm2'] = L.BatchNormalization(ch)\n",
    "        super().__init__(**layers)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        h = self.conv1(x)\n",
    "        if self.bn == True:\n",
    "            h = self.bnorm1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        if self.bn == True:\n",
    "            h = self.bnorm2(h)\n",
    "        h = h +x\n",
    "        h = F.relu(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(Chain):\n",
    "    def __init__(self, ch, bn=True):\n",
    "        layers = {}\n",
    "        layers['conv1'] = L.Convolution2D(ch,ch,1,1,0)\n",
    "        layers['conv2'] = L.Convolution2D(ch,ch,3,1,1)\n",
    "        layers['conv3'] = L.Convolution2D(ch,ch,1,1,0)\n",
    "        layers['bnorm1'] = L.BatchNormalization(ch)\n",
    "        layers['bnorm2'] = L.BatchNormalization(ch)\n",
    "        layers['bnorm3'] = L.BatchNormalization(ch)\n",
    "        super().__init__(**layers)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        h = self.conv1(x)\n",
    "        if self.bn == True:\n",
    "            h = self.bnorm1(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(h)\n",
    "        if self.bn == True:\n",
    "            h = self.bnorm2(h)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv3(h)\n",
    "        if self.bn == True:\n",
    "            h = self.bnorm3(h)\n",
    "        h = h +x\n",
    "        h = F.relu(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelShuffler(Chain):\n",
    "    def __init__(self,ch,r):\n",
    "        self.r = r\n",
    "        self.ch = ch\n",
    "        super().__init__()\n",
    "    \n",
    "    def __call__(self,x):    \n",
    "        batchsize,ch,Ny,Nx = x.shape\n",
    "        ch_y = ch//(self.r**2)\n",
    "        Ny_y = Ny*self.r\n",
    "        Nx_y = Nx*self.r\n",
    "        h = F.reshape(x, (batchsize, self.r, self.r, ch_y, Ny, Nx))\n",
    "        h =  F.transpose(h, (0, 3, 4, 1, 5, 2))\n",
    "        y = F.reshape(h, (batchsize, ch_y, Ny_y, Nx_y))\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBR(Chain):\n",
    "    def __init__(self, ch_in, ch_out, sample='down',bn=True,  act=F.relu, drop=False):\n",
    "        self.bn = bn\n",
    "        self.act = act\n",
    "        self.drop = drop\n",
    "\n",
    "        layers = {}\n",
    "        if sample=='down':\n",
    "            layers['conv'] = L.Convolution2D(ch_in, ch_out, 4, 2, 1)\n",
    "        else:\n",
    "            layers['conv'] = L.Deconvolution2D(ch_in, ch_out, 4, 2, 1)\n",
    "        if bn:\n",
    "            layers['bnorm'] = L.BatchNormalization(ch_out)\n",
    "        super().__init__(**layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        h = self.conv(x)\n",
    "        if self.bn == 1:\n",
    "            h = self.bnorm(h)\n",
    "        if self.drop == 1:\n",
    "            h = F.dropout(h)\n",
    "        h = self.act(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Chain):\n",
    "    def __init__(self, ch_in,ch_out):\n",
    "        initializer = Ini.HeNormal()\n",
    "        layers = {}\n",
    "        layers['conv1'] = L.Convolution2D(ch_in,ch_out,ksize=3,stride=2,pad=1)\n",
    "        layers['bnorm1'] = L.BatchNormalization(ch_out)\n",
    "        super().__init__(**layers)\n",
    "        \n",
    "    def __call__(self,x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bnorm1(h)\n",
    "        h = F.relu(h)\n",
    "        #h = F.max_pooling_2d(h,ksize=3,stride=2)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = ttrain.max() + 1\n",
    "H1 = 64\n",
    "H2 = 64\n",
    "H3 = 64\n",
    "\n",
    "NN = Chain(cnn1 = CNN(ch,H1),\n",
    "           cnn2 = CNN(H1,H2),\n",
    "           Rb1 = ResBlock(H2),\n",
    "           Rb2 = ResBlock(H2),\n",
    "                 l1=L.Linear(None,H3,initialW=initializer),\n",
    "                 l2=L.Linear(H3,C,initialW=initializer),\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ny = 31\n",
    "Nx = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: (1, 3, 31, 31)\n",
      "output: (1, 10, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(ch*Ny*Nx).reshape(1,ch,Ny,Nx).astype(np.float32)\n",
    "ohm.check_network(x,L.Convolution2D(ch,10,ksize=4,stride=2,pad=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    h = NN.cnn1(x)\n",
    "    h = NN.cnn2(h)\n",
    "    h = NN.Rb1(h)\n",
    "    h = NN.Rb2(h)\n",
    "    \n",
    "    h = F.dropout(NN.l1(h),0.5)\n",
    "    h = F.relu(h)\n",
    "    y = NN.l2(h)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_device = 2\n",
    "cuda.get_device(gpu_device).use()\n",
    "NN.to_gpu(gpu_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optNN = Opt.Adam()\n",
    "optNN.setup(NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "result = [train_loss,train_acc,test_loss,test_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "from IPython import display\n",
    "nepoch = 50\n",
    "%matplotlib inline\n",
    "import PIL.Image as im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_shift_labeled(labeled_data,h_shift=True,v_shift=True):\n",
    "    data, label = labeled_data\n",
    "    \n",
    "    [ch,Ny,Nx] = data.shape\n",
    "    z_h = Ny*(2.0*np.random.rand(1)-1.0)*h_shift*0.2\n",
    "    z_v = Nx*(2.0*np.random.rand(1)-1.0)*v_shift*0.2\n",
    "    data = np.roll(data,int(z_h),axis=1)\n",
    "    data = np.roll(data,int(z_v),axis=2)\n",
    "    \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_flip_labeled(labeled_data,h_flip=True,v_flip=True,rotate=True):\n",
    "    data, label = labeled_data\n",
    "    #horizontal flip\n",
    "    z = np.random.randint(2)\n",
    "    if z*h_flip == 1:\n",
    "        data = data[:,::-1,:]\n",
    "    \n",
    "    #vertical flip\n",
    "    z = np.random.randint(2)\n",
    "    if z*v_flip == 1:\n",
    "        data = data[:,:,::-1]\n",
    "\n",
    "    #rotate\n",
    "    z = np.random.randint(2)\n",
    "    if z*rotate== 1:\n",
    "        data = data.transpose(0,2,1)\n",
    "        \n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ds.TransformDataset(train, transform_flip_labeled)\n",
    "plt.imshow(batch[0][0].transpose(1,2,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_iter = siter(train, batch_size)    \n",
    "with tqdm(total=nepoch) as pbar:\n",
    "    while train_iter.epoch < nepoch:\n",
    "        batch = train_iter.next()\n",
    "        batch = ds.TransformDataset(batch, transform_flip_labeled)\n",
    "        batch = ds.TransformDataset(batch, transform_shift_labeled)\n",
    "        xtrain,ttrain = con.concat_examples(batch)\n",
    "        data = cuda.to_gpu([xtrain,xtest,ttrain,ttest])\n",
    "        ohm.learning_process_classification(model,optNN,data,result,100)\n",
    "        if train_iter.is_new_epoch == 1:\n",
    "            display.clear_output(wait=True)\n",
    "            ohm.plot_result2(result[0],result[1],'loss function in training','step','loss function',0.0,4.0)\n",
    "            ohm.plot_result2(result[2],result[3],'Accuracy in training and test','step','accuracy')\n",
    "            display.display(pl.gcf())\n",
    "        pbar.update(train_iter.is_new_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohm.plot_result2(result[0],result[1],'loss function in training','step','loss function',0.0,4.0)\n",
    "ohm.plot_result2(result[2],result[3],'Accuracy in training and test','step','accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(result[3][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
